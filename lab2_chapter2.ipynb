{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2 Chapter 2 Strings\n",
    "\n",
    "Almost every useful program involves some kind of text processing, whether it is parsing\n",
    "data or generating output. This chapter focuses on common problems involving text\n",
    "manipulation, such as pulling apart strings, searching, substitution, lexing, and parsing.\n",
    "Many of these tasks can be easily solved using built-in methods of strings. However,\n",
    "more complicated operations might require the use of regular expressions or the cre‐\n",
    "ation of a full-fledged parser. All of these topics are covered. In addition, a few tricky\n",
    "aspects of working with Unicode are addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 problem\n",
    "You need to split a string into fields, but the delimiters (and spacing around them) aren’t\n",
    "consistent throughout the string.\n",
    "\n",
    "- split only takes 1 delimitor\n",
    "- re split helps more because you cn have a pattern \n",
    "- using () in a re.split make a capture group which will be included in the reasults of the split\n",
    "- non capture group uses (?:....) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo', 'mike)', 'moore(']\n",
      "********************\n",
      "fielda:  ['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo', ' ', 'mike)', ' ', 'moore(']\n",
      "values:  ['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo', 'mike)', 'moore(']\n",
      "delimitera:  [' ', ';', ',', ',', ',', ' ', ' ', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "line = 'asdf fjdk; afed, fjek,asdf, foo mike) moore('\n",
    "print(re.split(r'[;,\\s]\\s*', line))\n",
    "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
    "print('*'*20)\n",
    "print('fielda: ', fields)\n",
    "values = fields[::2]\n",
    "delimiters = fields[1::2] + ['']\n",
    "\n",
    "print('values: ',values)\n",
    "print('delimitera: ',delimiters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 problem \n",
    "You need to check the start or end of a string for specific text patterns, such as filename extensions, URL schemes, and so on.\n",
    "\n",
    "- str.start_with\n",
    "- str.end_with\n",
    "- both methods take in a tuple, a list will throw an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "name = 'Michael'\n",
    "print(name.startswith('Mic'), name.endswith('ael'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Problem\n",
    "You want to match text using the same wildcard patterns as are commonly used when\n",
    "working in Unix shells (e.g., *.py, Dat[0-9]*.csv, etc.).\n",
    "\n",
    "- fnmatch import fnmatch, fnmatchcase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from fnmatch import fnmatch, fnmatchcase\n",
    "# on windows True\n",
    "print(fnmatch('foo.txt', '*.TXT'))\n",
    "print(fnmatchcase('foo.txt', '*.TXT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Problem\n",
    "You want to match or search text for a specific pattern.\n",
    "- simple literal, \n",
    "    - str.find(), str.endswith(), str.startswith(),\n",
    "- use re ( regular expression) to do more complicated things\n",
    "    - d+ one or more digit\n",
    "    - one or more\n",
    "    - $ if you want the exact match\n",
    "    \n",
    "- better to precompile a re if its going to be matched multiple times\n",
    "    - match capture the first match\n",
    "    - use findall to get all matches\n",
    "- using match can help seperate the group that match\n",
    "- better to use raw strings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 're.Match'>\n",
      "<re.Match object; span=(0, 10), match='11/27/2012'>\n",
      "group():  11/27/2012\n",
      "group(0):  11/27/2012\n",
      "group(1):  11\n",
      "group(2):  27\n",
      "group(3):  2012\n",
      "groups:  ('11', '27', '2012')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('11', '27', '2012'), ('3', '13', '2013')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "m = datepat.match('11/27/2012')\n",
    "print(type(m))\n",
    "print(m)\n",
    "print('group(): ',m.group())\n",
    "print('group(0): ',m.group(0))\n",
    "print('group(1): ',m.group(1))\n",
    "print('group(2): ',m.group(2))\n",
    "print('group(3): ',m.group(3))\n",
    "print('groups: ',m.groups())\n",
    "\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "datepat.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.5\n",
    "You want to search for and replace a text pattern in a string.\n",
    "\n",
    "- str.replace\n",
    "- for more complicated numbers use sub from the re module \n",
    "- \\3 <- the 3 represent the capture group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah, but na, but yeah, but na, but yeah\n",
      "text Today is 11/27/2012. PyCon starts 3/13/2013.\n",
      "text re sub: Today is 2012-11-27. PyCon starts 2013-3-13.\n"
     ]
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "print(text.replace('no', 'na'))\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "print('text',text)\n",
    "print('text re sub:',re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.6 \n",
    "You need to search for and possibly replace text in a case-insensitive manner.\n",
    "\n",
    "- re.IGNORECASE flag\n",
    "    - re.sub('python', 'snake', text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 problem\n",
    "You’re trying to match a text pattern using regular expressions, but it is identifying the longest possible matches of a pattern. Instead, you would like to change it to find the shortest possible match.\n",
    "\n",
    "- re ? - matches 0 or 1 occuance\n",
    "-    . - matches any character except \\n\n",
    "- noncapture group (i.e., it defines a group for the purposes of matching, but that group is not captured separately or numbered).\n",
    "-  re.DOTALL match all char including new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO.']\n",
      "['No.\" Phone says \"Yes.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "str_pat = re.compile(r'\\\"(.*)\\\"')\n",
    "text = 'Computer sayas \"NO.\"'\n",
    "print(str_pat.findall(text))\n",
    "text = 'Computer says \"No.\" Phone says \"Yes.\"'\n",
    "print(str_pat.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO.']\n",
      "['No.', 'Yes.']\n"
     ]
    }
   ],
   "source": [
    "str_pat = re.compile(r'\\\"(.*?)\\\"')\n",
    "text = 'Computer sayas \"NO.\"'\n",
    "print(str_pat.findall(text))\n",
    "text = 'Computer says \"No.\" Phone says \"Yes.\"'\n",
    "print(str_pat.findall(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Problem\n",
    "You’re trying to match a block of text using a regular expression, but you need the match\n",
    "to span multiple lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' this is a comment ']\n",
      "[]\n",
      "[' this is a\\n... multiline comment ']\n"
     ]
    }
   ],
   "source": [
    "comment_pat = re.compile(r'/\\*(.*?)\\*/')\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = '''/* this is a\n",
    "... multiline comment */\n",
    "... '''\n",
    "\n",
    "print(comment_pat.findall(text1))\n",
    "print(comment_pat.findall(text2))\n",
    "comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')\n",
    "# (?:..) =no grouping\n",
    "print(comment.findall(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 Problem\n",
    "You’re working with Unicode strings, but need to make sure that all of the strings have\n",
    "the same underlying representation.\n",
    "\n",
    "- first normalize the text into a standard representation using the unicodedata module\n",
    "- The first argument to normalize() specifies how you want the string normalized. \n",
    "- NFC means that characters should be fully composed (i.e., use a single code point if possible). \n",
    "- NFD means that characters should be fully decomposed with the use of combining characters.\n",
    "- NFKC and NFKD,\n",
    "- Normalization can also be an important part of sanitizing and filtering text. For example, suppose you want to remove all diacritical marks from some text (possibly for the purposes of searching or matching):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spicy Jalapeño\n",
      "Spicy Jalapeño\n",
      "False\n",
      "True\n",
      "asscii t1: 'Spicy Jalape\\xf1o'\n",
      "True\n",
      "asscii t1: 'Spicy Jalapen\\u0303o'\n"
     ]
    }
   ],
   "source": [
    "import unicodedata \n",
    "\n",
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "s2 = 'Spicy Jalapen\\u0303o'\n",
    "print(s1)\n",
    "print(s2)\n",
    "print(s1==s2)\n",
    "\n",
    "t1 = unicodedata.normalize('NFC',s1)\n",
    "t2 = unicodedata.normalize('NFC',s1)\n",
    "print(t1 == t2)\n",
    "print(f'asscii t1: {ascii(t1)}')\n",
    "\n",
    "t1 = unicodedata.normalize('NFD',s1)\n",
    "t2 = unicodedata.normalize('NFD',s1)\n",
    "print(t1 == t2)\n",
    "print(f'asscii t1: {ascii(t1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11 Problem\n",
    "You want to strip unwanted characters, such as whitespace, from the beginning, end, or\n",
    "middle of a text string.\n",
    "\n",
    "- strip is good when you want to remove char from left or fight\n",
    "- str.replace or re.sub for middle of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      hello      world   \n",
      "\n",
      "***str.strip()***\n",
      "\n",
      "hello      world\n",
      "***get rid of middle***\n",
      "helloworld\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '      hello      world   \\n'\n",
    "print(s)\n",
    "s = s.strip()\n",
    "print('***str.strip()***\\n')\n",
    "print(s)\n",
    "print('***get rid of middle***')\n",
    "print(s.replace('  ',''))\n",
    "re.sub('\\s+',' ',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12 Problem\n",
    "Some bored script kiddie has entered the text “pýtĥöñ” into a form on your web page\n",
    "and you’d like to clean it up somehow\n",
    "\n",
    "- str.translate()\n",
    "    - takes in a map for the translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:  pýtĥöñ\f",
      "is\tawesome\r\n",
      "\n",
      "a:  pýtĥöñ is awesome \n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = 'pýtĥöñ\\fis\\tawesome\\r\\n'\n",
    "print('s: ', s)\n",
    "remap = {\n",
    "    ord('\\t') : ' ',\n",
    "    ord('\\f'): ' ',\n",
    "    ord('\\r'): ' ',\n",
    "}\n",
    "a = s.translate(remap)\n",
    "print('a: ', a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.13 Problem\n",
    "You need to format text with some sort of alignment applied\n",
    "\n",
    "str.ljust\n",
    "str.rjust\n",
    "str.center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         HELLO WORLD\n",
      "HELLO WORLD         \n",
      "    HELLO WORLD     \n",
      "*********HELLO WORLD\n",
      "HELLO WORLD*********\n",
      "****HELLO WORLD*****\n",
      "\n",
      "*******format*******\n",
      "         HELLO WORLD\n",
      "HELLO WORLD         \n",
      "    HELLO WORLD     \n",
      "*******format*******\n",
      "=========HELLO WORLD\n",
      "HELLO WORLD=========\n",
      "====HELLO WORLD=====\n"
     ]
    }
   ],
   "source": [
    "text = \"HELLO WORLD\"\n",
    "print(text.rjust(20))\n",
    "print(text.ljust(20))\n",
    "print(text.center(20))\n",
    "print(text.rjust(20,'*'))\n",
    "print(text.ljust(20,'*'))\n",
    "print(text.center(20,'*'))\n",
    "print()\n",
    "print('format'.center(20,'*'))\n",
    "print(format(text,'>20'))\n",
    "print(format(text,'<20'))\n",
    "print(format(text,'^20'))\n",
    "print('format'.center(20,'*'))\n",
    "print(format(text,'=>20'))\n",
    "print(format(text,'=<20'))\n",
    "print(format(text,'=^20'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.14\n",
    "You want to combine many small strings together into a larger string.\n",
    "\n",
    "- join() method\n",
    "- str + str runs slow because it makes a new obj everytime\n",
    "- sep option in str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parts:  ['New', 'York', 'is', 'the', 'BEst', 'City', 'Ever!!!']\n",
      "NewYorkistheBEstCityEver!!!\n",
      "New York is the BEst City Ever!!!\n",
      "New, York, is, the, BEst, City, Ever!!!\n"
     ]
    }
   ],
   "source": [
    "parts = 'New York is the BEst City Ever!!!'.split()\n",
    "print('parts: ',parts)\n",
    "print(''.join(parts))\n",
    "print(' '.join(parts))\n",
    "print(', '.join(parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hot Burns cold freezes'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def something():\n",
    "    yield 'Hot'\n",
    "    yield 'Burns'\n",
    "    yield 'cold'\n",
    "    yield 'freezes'\n",
    "    \n",
    "something()\n",
    "' '.join(something())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.15 problem\n",
    "You want to create a string in which embedded variable names are substituted with a\n",
    "string representation of a variable’s value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mike has 10 messages\n",
      "Mike has 323 messages\n"
     ]
    }
   ],
   "source": [
    "s = '{name} has {n} messages'\n",
    "print(s.format(name='mike',n=10))\n",
    "name = 'Mike'\n",
    "n = 323\n",
    "print(s.format_map(vars()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.16 Problem\n",
    "You have long strings that you want to reformat so that they fill a user-specified number\n",
    "of columns.\n",
    "\n",
    "-textwrap module\n",
    "    -.fill(text,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look into my eyes, look into my eyes, the eyes, the eyes, the eyes, not around the eyes, don't look around the eyes, look into my eyes, you're under.\n",
      "\n",
      "Look into my eyes, look into my eyes, the eyes, the eyes, the eyes,\n",
      "not around the eyes, don't look around the eyes, look into my eyes,\n",
      "you're under.\n",
      "\n",
      "  Mike:  Look into my eyes, look into my eyes, the eyes, the eyes, the\n",
      "eyes, not around the eyes, don't look around the eyes, look into my\n",
      "eyes, you're under.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
    "the eyes, not around the eyes, don't look around the eyes, \\\n",
    "look into my eyes, you're under.\"\n",
    "\n",
    "print(s)\n",
    "print()\n",
    "print(textwrap.fill(s,70))\n",
    "print()\n",
    "print(textwrap.fill(s,70,initial_indent='  Mike:  '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os.terminal_size(columns=149, lines=41)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.get_terminal_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.17 Problem\n",
    "You want to replace HTML or XML entities such as &entity; or &#code; with their\n",
    "corresponding text. Alternatively, you need to produce text, but escape certain charac‐\n",
    "ters (e.g., <, >, or &).\n",
    "\n",
    "- use a parser first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im guessing this is a tag? \"<tag>text</tag>\"\n",
      "im guessing this is a tag? \"&lt;tag&gt;text&lt;/tag&gt;\"\n",
      "b'Spicy Jalape&#241;o'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-d6228d3da248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTMLParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHTMLParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/html/__init__.py\u001b[0m in \u001b[0;36munescape\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mHTML\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0mnamed\u001b[0m \u001b[0mcharacter\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mdefined\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'&'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_charref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_replace_charref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "s = 'im guessing this is a tag? \"<tag>text</tag>\"'\n",
    "print(s)\n",
    "import html\n",
    "print(html.escape(s, quote=False))\n",
    "\n",
    "s = 'Spicy Jalapeño'\n",
    "s = s.encode('ascii',errors='xmlcharrefreplace')\n",
    "print(s)\n",
    "\n",
    "import html\n",
    "from html.parser import HTMLParser\n",
    "p = HTMLParser()\n",
    "html.unescape(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.18 problem\n",
    "You have a string that you want to parse left to right into a stream of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'foo = 23 + 42 * 10'\n",
    "token = [('NAME','foo'), ('EQ','='), ('NUM','23'), ('PLUS','+'), ('NUM','42'),('TIMES','*'), ('NUM','10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='foo'>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner = master_pat.scanner('foo = 42')\n",
    "scanner.match()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NAME', 'foo')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.lastgroup,_.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(3, 4), match=' '>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.match()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WS', ' ')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.lastgroup,_.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(4, 5), match='='>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('EQ', '=')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.lastgroup,_.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(5, 6), match=' '>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WS', ' ')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.lastgroup,_.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(6, 8), match='42'>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUM', '42')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.lastgroup,_.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Token = namedtuple('Token',['type','value'])\n",
    "\n",
    "def generate_token(pat,text):\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        yield Token(m.lastgroup,m.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='NUM', value='42')\n"
     ]
    }
   ],
   "source": [
    "for tok in generate_token(master_pat,'foo = 42'):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='NUM', value='23')\n",
      "Token(type='PLUS', value='+')\n",
      "Token(type='NUM', value='42')\n",
      "Token(type='TIMES', value='*')\n",
      "Token(type='NUM', value='10')\n"
     ]
    }
   ],
   "source": [
    "tokens = (tok for tok in generate_token(master_pat,text) if tok.type != 'WS')\n",
    "for tok in tokens:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.19 Problem\n",
    "You need to parse text according to a set of grammar rules and perform actions or build\n",
    "an abstract syntax tree representing the input. The grammar is small, so you’d prefer to\n",
    "just write the parser yourself as opposed to using some kind of framework.\n",
    "\n",
    "- you should probably start by having a formal specification of the grammar in the form of a BNF or EBNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
